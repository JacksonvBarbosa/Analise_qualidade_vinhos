{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20724857",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "\"cells\": [\n",
    "{\n",
    "\"cell_type\": \"markdown\",\n",
    "\"metadata\": {\n",
    "\"language\": \"markdown\"\n",
    "},\n",
    "\"source\": [\n",
    "\"# Simulação do fluxo model_builder\\n\",\n",
    "\"Este notebook carrega os dados, aplica a engenharia de features, divide treino/teste, testa várias combinações de algoritmos e métodos de balanceamento, e inspeciona os parâmetros do melhor pipeline.\\n\",\n",
    "\"Execute as células sequencialmente.\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"cell_type\": \"code\",\n",
    "\"metadata\": {\n",
    "\"language\": \"python\"\n",
    "},\n",
    "\"source\": [\n",
    "\"# Imports principais\\n\",\n",
    "\"import pandas as pd\\n\",\n",
    "\"import json\\n\",\n",
    "\"from pprint import pprint\\n\",\n",
    "\"\\n\",\n",
    "\"# Funções/objetos do projeto\\n\",\n",
    "\"from analise_qualidade_vinhos.data.dataset import load_featured_data, train_test_split_featured\\n\",\n",
    "\"from analise_qualidade_vinhos.pipeline import model_builder\\n\",\n",
    "\"from analise_qualidade_vinhos.pipeline.model_builder import (\\n\",\n",
    "\" build_training_pipeline,\\n\",\n",
    "\" test_multiple_algorithms,\\n\",\n",
    "\" build_best_pipeline,\\n\",\n",
    "\" get_class_labels,\\n\",\n",
    "\")\\n\",\n",
    "\"\\n\",\n",
    "\"# Mostrar versões úteis\\n\",\n",
    "\"import sklearn\\n\",\n",
    "\"print('pandas', pd.version)\\n\",\n",
    "\"print('sklearn', sklearn.version)\\n\",\n",
    "\"try:\\n\",\n",
    "\" import xgboost\\n\",\n",
    "\" print('xgboost', xgboost.version)\\n\",\n",
    "\"except Exception:\\n\",\n",
    "\" print('xgboost: não instalado')\\n\",\n",
    "\"try:\\n\",\n",
    "\" import lightgbm\\n\",\n",
    "\" print('lightgbm', lightgbm.version)\\n\",\n",
    "\"except Exception:\\n\",\n",
    "\" print('lightgbm: não instalado')\\n\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"cell_type\": \"markdown\",\n",
    "\"metadata\": {\n",
    "\"language\": \"markdown\"\n",
    "},\n",
    "\"source\": [\n",
    "\"## 1) Carregar dados com as features prontos\\n\",\n",
    "\"A função load_featured_data usa build_feature_matrix do pacote features. Se preferir inspecionar o CSV cru, use load_raw_data().\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"cell_type\": \"code\",\n",
    "\"metadata\": {\n",
    "\"language\": \"python\"\n",
    "},\n",
    "\"source\": [\n",
    "\"# Carrega os dados (usa o RAW_DATA_PATH definido em settings se não passar caminho).\\n\",\n",
    "\"df = load_featured_data()\\n\",\n",
    "\"print('Shape:', df.shape)\\n\",\n",
    "\"display(df.head())\\n\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"cell_type\": \"markdown\",\n",
    "\"metadata\": {\n",
    "\"language\": \"markdown\"\n",
    "},\n",
    "\"source\": [\n",
    "\"## 2) Separar X e y (treino/teste)\\n\",\n",
    "\"Usamos train_test_split_featured que espera a coluna TARGET_COLUMN já presente no DataFrame (definida em settings).\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"cell_type\": \"code\",\n",
    "\"metadata\": {\n",
    "\"language\": \"python\"\n",
    "},\n",
    "\"source\": [\n",
    "\"# Split em treino/teste\\n\",\n",
    "\"X_train, X_test, y_train, y_test = train_test_split_featured(df)\\n\",\n",
    "\"print('X_train', X_train.shape, 'X_test', X_test.shape)\\n\",\n",
    "\"print('y_train distribution:')\\n\",\n",
    "\"display(y_train.value_counts(normalize=True))\\n\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"cell_type\": \"markdown\",\n",
    "\"metadata\": {\n",
    "\"language\": \"markdown\"\n",
    "},\n",
    "\"source\": [\n",
    "\"## 3) Construir um pipeline simples e inspecionar parâmetros\\n\",\n",
    "\"Vamos criar um pipeline com random_forest + smoteenn e ver os parâmetros do pré-processador e do modelo.\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"cell_type\": \"code\",\n",
    "\"metadata\": {\n",
    "\"language\": \"python\"\n",
    "},\n",
    "\"source\": [\n",
    "\"pipeline = build_training_pipeline(algorithm='random_forest', balance_method='smoteenn')\\n\",\n",
    "\"print('Pipeline steps:')\\n\",\n",
    "\"pprint(pipeline.steps)\\n\",\n",
    "\"\\n\",\n",
    "\"# Mostrar parâmetros em alto nível\\n\",\n",
    "\"print('\\nPipeline get_params (chaves relevantes):')\\n\",\n",
    "\"for k in sorted(pipeline.get_params()):\\n\",\n",
    "\" if any(prefix in k for prefix in ['model', 'preprocess', 'balance']):\\n\",\n",
    "\" print(k)\\n\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"cell_type\": \"markdown\",\n",
    "\"metadata\": {\n",
    "\"language\": \"markdown\"\n",
    "},\n",
    "\"source\": [\n",
    "\"## 4) Treinar o pipeline e ver métricas simples\\n\",\n",
    "\"Treinamos e avaliamos accuracy e f1_weighted.\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"cell_type\": \"code\",\n",
    "\"metadata\": {\n",
    "\"language\": \"python\"\n",
    "},\n",
    "\"source\": [\n",
    "\"pipeline.fit(X_train, y_train)\\n\",\n",
    "\"preds = pipeline.predict(X_test)\\n\",\n",
    "\"\\n\",\n",
    "\"from sklearn.metrics import accuracy_score, f1_score, classification_report\\n\",\n",
    "\"acc = accuracy_score(y_test, preds)\\n\",\n",
    "\"f1w = f1_score(y_test, preds, average='weighted')\\n\",\n",
    "\"print(f'Accuracy: {acc:.4f} | F1 weighted: {f1w:.4f}')\\n\",\n",
    "\"print('\\nClassification report:')\\n\",\n",
    "\"print(classification_report(y_test, preds))\\n\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"cell_type\": \"markdown\",\n",
    "\"metadata\": {\n",
    "\"language\": \"markdown\"\n",
    "},\n",
    "\"source\": [\n",
    "\"## 5) Testar múltiplos algoritmos e métodos de balanceamento\\n\",\n",
    "\"Use test_multiple_algorithms para rodar combinações. Isso pode levar algum tempo dependendo do conjunto e dos modelos disponíveis.\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"cell_type\": \"code\",\n",
    "\"metadata\": {\n",
    "\"language\": \"python\"\n",
    "},\n",
    "\"source\": [\n",
    "\"# Opcional: reduzir lista (para execução mais rápida durante experimentos)\\n\",\n",
    "\"algorithms = ['random_forest', 'gradient_boosting']\\n\",\n",
    "\"if getattr(model_builder, 'XGBOOST_AVAILABLE', False):\\n\",\n",
    "\" algorithms.append('xgboost')\\n\",\n",
    "\"if getattr(model_builder, 'LIGHTGBM_AVAILABLE', False):\\n\",\n",
    "\" algorithms.append('lightgbm')\\n\",\n",
    "\"\\n\",\n",
    "\"balance_methods = ['smoteenn', 'adasyn', 'smote']\\n\",\n",
    "\"\\n\",\n",
    "\"results = test_multiple_algorithms(X_train, y_train, X_test, y_test, algorithms=algorithms, balance_methods=balance_methods)\\n\",\n",
    "\"\\n\",\n",
    "\"print('\\nResultados resumidos:')\\n\",\n",
    "\"for key, res in results.items():\\n\",\n",
    "\" if 'f1_weighted' in res:\\n\",\n",
    "\" print(key, '->', f\"F1={res['f1_weighted']:.4f}\", f\"Acc={res['accuracy']:.4f}\")\\n\",\n",
    "\" else:\\n\",\n",
    "\" print(key, '-> ERROR:', res.get('error'))\\n\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"cell_type\": \"markdown\",\n",
    "\"metadata\": {\n",
    "\"language\": \"markdown\"\n",
    "},\n",
    "\"source\": [\n",
    "\"## 6) Retreinar o melhor pipeline no treino completo\\n\",\n",
    "\"build_best_pipeline procura o melhor por F1 weighted, reconstrói e retreina sobre o conjunto de treino.\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"cell_type\": \"code\",\n",
    "\"metadata\": {\n",
    "\"language\": \"python\"\n",
    "},\n",
    "\"source\": [\n",
    "\"best_pipeline = build_best_pipeline(X_train, y_train, X_test, y_test)\\n\",\n",
    "\"print('\\nMelhor pipeline treinada:')\\n\",\n",
    "\"print(best_pipeline)\\n\",\n",
    "\"\\n\",\n",
    "\"# Inspecionar o estimador final e seus parâmetros\\n\",\n",
    "\"model_final = best_pipeline.named_steps['model']\\n\",\n",
    "\"print('\\nModelo final: ', type(model_final))\\n\",\n",
    "\"pprint(model_final.get_params())\\n\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"cell_type\": \"markdown\",\n",
    "\"metadata\": {\n",
    "\"language\": \"markdown\"\n",
    "},\n",
    "\"source\": [\n",
    "\"## 7) Salvar resultados e o pipeline (opcional)\\n\",\n",
    "\"Você pode salvar o pipeline com joblib ou pickle caso queira reutilizar depois.\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"cell_type\": \"code\",\n",
    "\"metadata\": {\n",
    "\"language\": \"python\"\n",
    "},\n",
    "\"source\": [\n",
    "\"# Salvar o pipeline treinado em models/\\n\",\n",
    "\"import joblib\\n\",\n",
    "\"from pathlib import Path\\n\",\n",
    "\"out_dir = Path('models')\\n\",\n",
    "\"out_dir.mkdir(exist_ok=True)\\n\",\n",
    "\"model_path = out_dir / 'best_pipeline.joblib'\\n\",\n",
    "\"joblib.dump(best_pipeline, model_path)\\n\",\n",
    "\"print('Pipeline salvo em', model_path)\\n\",\n",
    "\"\\n\",\n",
    "\"# Salvar métricas em JSON\\n\",\n",
    "\"metrics_path = out_dir / 'training_results.json'\\n\",\n",
    "\"simple_results = {k: {kk: vv for kk, vv in v.items() if kk in ('accuracy','f1_weighted','algorithm','balance')} for k, v in results.items()}\\n\",\n",
    "\"metrics_path.write_text(json.dumps(simple_results, indent=2))\\n\",\n",
    "\"print('Métricas salvas em', metrics_path)\\n\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"cell_type\": \"markdown\",\n",
    "\"metadata\": {\n",
    "\"language\": \"markdown\"\n",
    "},\n",
    "\"source\": [\n",
    "\"## Dicas finais\\n\",\n",
    "\"- Se você quiser inspecionar importâncias de features, verifique se o modelo final expõe feature_importances_ (RandomForest, GradientBoosting, LightGBM). Para XGBoost use get_booster()/feature_importances_ conforme disponível.\\n\",\n",
    "\"- Para acelerar experimentos, reduza n_estimators nos modelos ou use uma amostra menor do conjunto de treino.\\n\",\n",
    "\"- Se ocorrer erro por colunas faltantes em NUMERIC_FEATURES, execute df.columns e compare com model_builder.NUMERIC_FEATURES e ajuste a engenharia de features.\\n\"\n",
    "]\n",
    "}\n",
    "]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
